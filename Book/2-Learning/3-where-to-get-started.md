title: Where to get started
----
content:

The first step to learning something is to learn about the different avenues of actually starting. Web development is very much the same and as sad as it is, most new web developers have no idea how to approach this, and what to recommend others.

Every developer has their story and some developers sternly believe that their story and experience is the correct path to being a developer. Others, like me, realize that there are many ways to accomplish a goal. In this case, web development has countless avenues that lead to working as a full-pledged developer.

The order of learning web development topics is very much discussed. I'll present you with my idea but you're welcome to ask around. Computer Science people may insist that you learn programming first, self-taught web developers may insist on the HTML/CSS basics. Below is a list of what I personally recommend from seeing it work time and time again:

1. HTML - so you can build your first website
2. CSS - so you can style your first website. This gives you an ability to build full (albeit static) websites
3. First server-side language - you can read through the list again to check out which one. This is going to require learning programming. But now, you'll be able to build dynamic websites
4. SQL - SQL is a language that you can use to retrieve data from a database. This topic will probably be part of your server-side language learning.
4. Javascript - to get a feel for the front-end and work from there.
5. Server-side framework/cms - This will give you the ability to start doing some real work.
6. Go from there. Whether it's mastering another language, or a front-end framework, or any number of tools, it's up to you and where you choose to go.

It sounds straightforward and that's because it is, at least in the beginning.

## College vs Online Courses

First and foremost, I'm not a big fan of college; however, there are many times that I reference college material and even take online college courses to fill the gaps in my knowledge. As well, I hear developers argue back and forth on this topic tirelessly. The arguing should be something you get used to, it's part of the web development world.

On the one hand, college education can provide a wide breadth of knowledge, and many opportunities to test your skills and have your skills critiqued. On the other, online courses can throw you right into the field and have you gaining real hands-on experience right away.

### College

After conducting a few personal surveys, I got the following answer as to why a web developer should go to college first:

1. College provides people with great connections. Classmates can quickly become CEOs, teachers can recommend former students, and other classmates can become co-workers.
2. You will acquire a wide-breadth of knowledge outside of the web development field. Such as knowledge of design patterns, algorithms, and other information.
3. A degree can help you jumpstart your career.
4. Most Facebook + Google engineers have a CS degree.

And some of these I agree with, particularly point \#2. To that point, there are several topics that Online Courses truly don't focus on whatsoever:

1. Algorithms - a better way to say this is "common algorithms" which is basically to say, programming procedures that are either efficient or inefficient. They're patterns of code that follow a certain logic. For instance, there is a "Quicksort" algorithm which specifies an efficient way to programmatically sort a list of items. The code may differ among programmers that implement it but the logic is the same.
2. Design patterns - a design pattern is a way of structuring an application or solving an application-specific problem. Unlike algorithms, we're not manipulating anything, mainly "organizing" a way an application works. For instance, there is a design pattern called Dependency Injection which states that any part of your application which requires another part or library to work (a dependency) should not be responsible for retrieving that part/library. Instead, there should be a module/library or a part of your application whose sole focus is providing the rest of the application with proper dependencies. Sounds a little complicated, I know.
3. Low-level to high-level overview - Web development is very close to the Apex of programming. A single line of code accomplishes that which lower-level languages use entire libraries for. That's a good thing and a bad thing. It provides great power but it also limits what you *can* do. Seeing programming all the way from Assembly through C, C++, Java, other languages and finally to web development can be enlightening.
4. Various languages - Learning various languages helps developers understand how the language they're using is unique and how to take advantage of it. It also helps with looking at problems from different angles since different languages operate on slightly different programming paradigms.

Most self-taught developers I've met never bothered to look at any of these topics and thus missed out on becoming better developers, or at least "good" developers. Especially in enterprise environments, these topics are important to learn and cannot be ignored.

College forces the topics on you and even though they may be forgotten, there's still an inherent familiarity with them.

There are several problems with attending college, however, and they cannot be brushed off:

1. It takes too long, at least 4 years is a long time. No longer than any other degree but a long time nonetheless.
2. It's expensive. Especially in the US. A CS degree may cost you upward of 8K a semester just in classes and books.
3. Most jobs won't give you a position straight out of college. So you either have to struggle to find one miraculous employer that will hire you after college or find time to work along with your studies.
4. What you learn may not necessarily apply to what you do and what you may learn may not necessarily be up to date.

So, as always, there's a decision to be made. I can tell you from personal experience that most employers value college as "two years worth of work experience" once you have at least one year of actual work experience. At least there's that.

### Self-taught

Being self-taught has become a symbol of a web developer because even when you make your way out of college, additional topics to learn will be your own responsibility, not some course, certification, or additional degrees. However, we're not talking about the distant future, we're talking about today.

So here is a list of skills that self-taught developers like to highlight in their learning experiences:

1. They learn what they need as they need it, and use it - This can be a great advantage since any knowledge you acquired can be directly used right away. This includes those pesky "wide-breadth" knowledge factors which can be learned ONLY when they're necessary.
2. Work and client experience can quickly shape your career. Those few extra years of working with clients or at agencies can quickly convert to a rising career. There's a great deal of hands-on experience and learning from mentors. On top of that, you quickly gain contacts with people that have a need for developers.
3. The learning community creates great connections. There are entire communities of future web developers that get help from seasoned programmers and other people on their path. The web development community is a great one to join
4. The entire process is cheap with little commitment and great pay-offs for the work.
5. Self-reliance, learning through review, problem solving, and situational problem solving.

For this list, I'd like to focus on \#1 which is the most important one. There are typical concerns with college-learned developers and one of them is thinking in terms of Academia rather than problem solving. This can lead to overuse of the aforementioned algorithms and design patterns.

College graduates are often seen to over-engineer and over-complicate their work or get frustrated quickly with a problem that doesn't fit regular paremeters. This leads to companies avoiding college graduates until they're vetted through some other company for at least a year.

In essence, it's the difference between having a developer that can "duct tape" a problem and know what kind of issues that can cause and a developer that either cannot find a solution or can find a solution which would take several times the amount of time to implement and would cause issues.

But as always, there are some downsides to being a self-taught developer:

1. Older companies that are used to the "college-degree-only" hiring process will pass you over
2. You will always have to take the initiative to learn more and learn more deeply about computer science on your own. That can be difficult and discouraging.
3. Creating connections is on you and on you to find the right environment for it.
4. Seeing college graduates fill prestigious roles (at Google, Facebook, and other big tech companies) can be discouraging when job hunting.

As before, I would like to warn you that some employers require degrees but most tech companies do not. And some that do will let you slide by if you have about 2 years worth of working experience.

## The Choice is yours

As always, the choice is yours. There is no "better way" despite what people may tell you. What I do recommend is reading through the rest of this book and learning about what it takes to be a web developer and what it takes to be a good web developer. At least that will prepare you better for your decision.

Also, I recommend getting involved in the web development community. Whether it's on [Reddit](http://reddit.com/r/webdev), [Dzone](http://www.dzone.com/links/index.html), [HackerNews](https://news.ycombinator.com/), or other websites. It's good to be there, to ask questions, to read people's concerns, and to read through past discussions on this very topic. People do get heated but if you look past their ego, you'll see a grain of wisdom that may apply to specifically you.

Outside of that, there are a few general recommendations and words of wisdom to share with you:

1. If you're in college, it's a good idea to take on freelance or community project for some experience. These may not pay much or they may pay so much you'll drop out.
2. Start learning ASAP, don't wait for the right moment. Even if you're in the first year of college, learn some HTML or follow some online tutorials, just to get a feel for it.
3. It doesn't matter what age you are. There are 40 and 50 year olds learning HTML/CSS. At one of my talks, there was a lady that was at least 65 or 70 asking the most hardcore questions and sporting her Surface. There were also teenagers that probably haven't even graduated from High School yet.
4. If you're in it partially for the money, be practical. By that, I mean, do your calculations and figure out what works best for you and what will drive most of the profit. If you want to get involved with startups, a degree will probably mean less there. If you want to get involved in Enterprise work, you might want to have a CS degree (though not necessarily).
5. Think about your learning style, keep that in mind as you choose a route.
6. And no one said you can't combine the two.

I encourage you to share your story somehow as you progress. Either on the aforementioned community sites or through your blog. New developers and prospective developers love seeing someone's progress and hearing their stories because yours may match up exactly to someone else's dream.
